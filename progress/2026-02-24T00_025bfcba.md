# Progress: 2026-02-24 — Session 025bfcba

**Type**: Implementation (worker)
**Issue**: #127 — Prove inflateLoop_complete

## Accomplished

### Deliverable 1: Prove inflateLoop_complete for all btype cases — COMPLETE

Proved `inflateLoop_complete` in `Zip/Spec/InflateCorrect.lean` — the
reverse direction of `inflateLoop_correct`. When the spec's `decode.go`
succeeds with some fuel, the native `inflateLoop` also succeeds and
produces the same output. Covers all three block types:

- **btype=0 (stored)**: Uses `decodeStored_complete` with output size
  bound from `decode_go_acc_prefix`.
- **btype=1 (fixed Huffman)**: Uses `decodeHuffman_complete` with fixed
  table bridges.
- **btype=2 (dynamic Huffman)**: Uses `decodeDynamicTrees_complete` +
  `decodeHuffman_complete` with UInt8 roundtrip bridges.
- **btype≥3**: Contradiction (spec returns none for reserved types).

### Deliverable 2: inflate_complete chains correctly — VERIFIED

`inflate_complete` in `DeflateFixedCorrect.lean` was already proved by
a previous session using `inflateLoop_complete` (with sorry). Now that
`inflateLoop_complete` is proved, `inflate_complete` is fully verified
with no sorry.

### Helper lemma: decode_go_acc_prefix — COMPLETE

Added `decode_go_acc_prefix` in `Zip/Spec/Deflate.lean` proving that
`decode.go` always extends the accumulator: if `decode.go bits acc fuel
= some result` then `acc <+: result`. This is essential for proving
the output size bound needed by `decodeStored_complete` and
`decodeHuffman_complete` in the non-final block case.

## Key proof patterns

- **Nat↔UInt32 bfinal bridging**: Added `nat_beq_to_uint32_true` and
  `nat_beq_to_uint32_false` for the reverse direction (spec Nat → native
  UInt32). Forward direction (`bfinal_beq_nat_true/false`) already existed.

- **UInt32 match reduction**: After simp substitutes `btype_val.toUInt32`
  into `inflateLoop`'s match, `Nat.toUInt32 N` doesn't auto-reduce.
  Solution: `simp only [...]; rfl` — after simp substitutes all operations,
  `rfl` handles the definitional equality.

- **ByteArray equality for stored blocks**: Use `ByteArray.ext` +
  `simp [ByteArray.data_append, heq]` to show `output ++ ⟨⟨storedBytes⟩⟩ = ⟨⟨result⟩⟩`.

- **UInt8 roundtrip for dynamic blocks**: Bridge `litLens` ↔
  `(litLens.map Nat.toUInt8).toArray.toList.map UInt8.toNat` using
  `List.map_congr_left` with `Nat.mod_eq_of_lt` from `ValidLengths`.

## Sorry count

- Start: 4 (3 in DeflateFixedCorrect.lean, 1 in InflateCorrect.lean)
- End: 3 (3 in DeflateFixedCorrect.lean)
- Delta: -1 (`inflateLoop_complete` sorry eliminated)

## What remains

The 3 remaining sorries are roundtrip theorems in DeflateFixedCorrect.lean:
- `inflate_deflateFixed`
- `inflate_deflateLazy`
- `inflate_deflateDynamic`

These depend on additional compressor-side correspondence proofs.
