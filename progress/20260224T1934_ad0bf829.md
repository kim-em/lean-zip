# Progress: Binary LE read/write roundtrip proofs

- **Date**: 2026-02-24T19:34Z
- **Session**: ad0bf829 (worker)
- **Issue**: #221

## What was accomplished

All deliverables completed:

1. **readUInt16LE_writeUInt16LE** — roundtrip for UInt16 LE read/write
2. **readUInt32LE_writeUInt32LE** — roundtrip for UInt32 LE read/write
3. **readUInt32LE_bytes** — inline-byte variant matching gzip/zlib encoder pattern
   (proves that the `(v &&& 0xFF).toUInt8, ((v >>> 8) &&& 0xFF).toUInt8, ...`
   pattern used in gzip/zlib trailers reads back correctly)
4. **Concatenation-aware variants** — all four:
   - `readUInt32LE_append_left` / `readUInt32LE_append_right`
   - `readUInt16LE_append_left` / `readUInt16LE_append_right`

## Proof strategy

- **Literal ByteArray access**: `getElem!` on `ByteArray.mk #[a, b, c, d]`
  reduces by `rfl` for concrete indices. Used private `ba4_getElem!_N` lemmas
  to reduce array accesses before `bv_decide`.
- **Core bitvector identities**: `bv_decide` closes all roundtrip goals
  after array access reduction (e.g., `val.toUInt8.toUInt32 ||| ... = val`).
- **Concatenation**: Bridged `getElem!` (bang access) to stdlib's
  `ByteArray.getElem_append_left`/`_right` via `getElem!_pos`.
  Used explicit `rw` rather than `simp only` or `congr` to avoid
  deterministic timeouts from whnf on UInt32 terms.

## Key pattern discovered

**`congr` timeouts on UInt32 goals**: `congr 1` on goals involving
UInt32 operations triggers full `whnf` reduction and deterministic
timeout. Use explicit `rw` with named lemmas instead.

## Sorry count

- Before: 0
- After: 0

## Files changed

- `Zip/Spec/BinaryCorrect.lean` — new (113 lines)
- `Zip.lean` — added import
- `.claude/CLAUDE.md` — updated source layout
